<!DOCTYPE html>
<html lang="">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('https://bruceeezhao.github.io').hostname,
    root: '/',
    scheme: 'Muse',
    version: '7.5.0',
    exturl: false,
    sidebar: {"position":"left","display":"always","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="1. Hadoop初识">
<meta name="keywords" content="大数据,Hadoop">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop">
<meta property="og:url" content="https://bruceeezhao.github.io/2020/11/05/Hadoop/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="1. Hadoop初识">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://bruceeezhao.github.io/2020/11/05/Hadoop/Hadoop1vs2.png">
<meta property="og:image" content="https://bruceeezhao.github.io/2020/11/05/Hadoop/hdfsarchitecture.png">
<meta property="og:image" content="https://bruceeezhao.github.io/2020/11/05/Hadoop/yarn_architecture.gif">
<meta property="og:image" content="https://bruceeezhao.github.io/2020/11/05/Hadoop/hdfsarchitecture.png">
<meta property="og:image" content="https://bruceeezhao.github.io/2020/11/05/Hadoop/writeProcess.png">
<meta property="og:image" content="https://bruceeezhao.github.io/2020/11/05/Hadoop/replicaSelection.png">
<meta property="og:image" content="https://bruceeezhao.github.io/2020/11/05/Hadoop/datanodeDistance.png">
<meta property="og:image" content="https://bruceeezhao.github.io/2020/11/05/Hadoop/readProcess.png">
<meta property="og:image" content="https://bruceeezhao.github.io/2020/11/05/Hadoop/namenodeWork.png">
<meta property="og:image" content="https://bruceeezhao.github.io/2020/11/05/Hadoop/datanodeWork.png">
<meta property="og:updated_time" content="2020-11-13T13:03:43.730Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hadoop">
<meta name="twitter:description" content="1. Hadoop初识">
<meta name="twitter:image" content="https://bruceeezhao.github.io/2020/11/05/Hadoop/Hadoop1vs2.png">

<link rel="canonical" href="https://bruceeezhao.github.io/2020/11/05/Hadoop/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Hadoop | Hexo</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hexo</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="default">
    <link itemprop="mainEntityOfPage" href="https://bruceeezhao.github.io/2020/11/05/Hadoop/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="bruce zhao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Hadoop
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-11-05 19:44:48" itemprop="dateCreated datePublished" datetime="2020-11-05T19:44:48+08:00">2020-11-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-11-13 21:03:43" itemprop="dateModified" datetime="2020-11-13T21:03:43+08:00">2020-11-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/大数据/" itemprop="url" rel="index">
                    <span itemprop="name">大数据</span>
                  </a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><img src="//bruceeezhao.github.io/2020/11/05/Hadoop/Hadoop1vs2.png" alt></p><h1 id="1-Hadoop初识"><a href="#1-Hadoop初识" class="headerlink" title="1. Hadoop初识"></a>1. Hadoop初识</h1><a id="more"></a>
<h2 id="1-1-Hadoop1-x-与-2-x的区别"><a href="#1-1-Hadoop1-x-与-2-x的区别" class="headerlink" title="1.1. Hadoop1.x 与 2.x的区别"></a>1.1. Hadoop1.x 与 2.x的区别</h2><p>如首图所示，在1.x中MapReduce负责计算和资源调度，在2.x中，将资源调度的功能从MapReduce中分离出来，增加了Yarn模块。</p>
<h2 id="1-2-HDFS架构"><a href="#1-2-HDFS架构" class="headerlink" title="1.2. HDFS架构"></a>1.2. HDFS架构</h2><p><a href="https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html" target="_blank" rel="noopener">HDFS文档</a></p>
<p><img src="//bruceeezhao.github.io/2020/11/05/Hadoop/hdfsarchitecture.png" alt></p>
<ol>
<li>NameNode: 存储文件的元数据，如文件名，文件目录结构，文件属性（生成时间、副本数、文件权限），以及每个文件的块列表和块所在的DataNode等</li>
<li>DataNode: 在本地文件系统存储文件块数据，以及块数据的校验和</li>
<li>Secondary NameNode：用来监控HDFS状态的辅助后台程序，每隔一段时间获取HDFS元数据的快照</li>
</ol>
<h2 id="1-3-Yarn架构"><a href="#1-3-Yarn架构" class="headerlink" title="1.3. Yarn架构"></a>1.3. Yarn架构</h2><p><a href="https://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html" target="_blank" rel="noopener">Yarn文档</a></p>
<p><img src="//bruceeezhao.github.io/2020/11/05/Hadoop/yarn_architecture.gif" alt></p>
<ol>
<li><p>Resource Manager:的主要功能</p>
<ol>
<li>处理客户端请求</li>
<li>监控NodeManager</li>
<li>启动或监控ApplicationMaster</li>
<li>资源的分配与调度</li>
</ol>
</li>
<li><p>NodeManager:的主要功能</p>
<ol>
<li>管理单个节点上的资源</li>
<li>处理来自Resource Manager的命令</li>
<li>处理来自ApplicationMaster的命令</li>
</ol>
</li>
<li><p>ApplicationMaste:</p>
<ol>
<li>负责数据的切分</li>
<li>为应用程序申请资源与分配给内部的任务</li>
<li>任务的监控与容错</li>
</ol>
</li>
<li><p>Container</p>
<p>Container是Yarn中的资源抽象，它封装了某个节点上的多维度资源，如内存、CPU、磁盘、网络等。</p>
</li>
</ol>
<h2 id="1-4-MapReduce"><a href="#1-4-MapReduce" class="headerlink" title="1.4. MapReduce"></a>1.4. MapReduce</h2><p><a href="http://hadoop.apache.org/docs/r1.2.1/mapred_tutorial.html" target="_blank" rel="noopener">MapReduce文档</a></p>
<p>MapReduce将计算过程分为两个阶段：Map和Redece</p>
<p>1) Map阶段并行处理输入数据</p>
<p>2) Reduce阶段对Map结果进行汇总</p>
<h1 id="2-HDFS"><a href="#2-HDFS" class="headerlink" title="2. HDFS"></a>2. HDFS</h1><p>使用场景：适合一次写入，多次读出的场景，且不支持文件修改。适合用来做数据分析。</p>
<h2 id="2-1-优缺点"><a href="#2-1-优缺点" class="headerlink" title="2.1. 优缺点"></a>2.1. 优缺点</h2><h3 id="2-1-1-优点"><a href="#2-1-1-优点" class="headerlink" title="2.1.1. 优点"></a>2.1.1. 优点</h3><ol>
<li>高容错性<ol>
<li>数据自动保存多个副本，通过增加副本的形式提高容错性。</li>
<li>某一个副本丢失后，会自动创建新的副本，保证副本的数量</li>
</ol>
</li>
<li>适合处理大数据<ol>
<li>数据规模：能够处理GB,TB甚至PB级的数据</li>
<li>文件规模：能够处理百万规模以上的文件数量</li>
</ol>
</li>
<li>可在廉价机上构建</li>
</ol>
<h3 id="2-1-2-缺点"><a href="#2-1-2-缺点" class="headerlink" title="2.1.2. 缺点"></a>2.1.2. 缺点</h3><ol>
<li>不适合低延时数据访问，比如毫秒级</li>
<li>无法高效的对大量小文件进行存储<ol>
<li>存储小文件会占用NameNode大量的内存来存储文件目录和块信息。</li>
<li>小文件存储的寻址时间会超过读取时间</li>
</ol>
</li>
<li>不支持并发写入，文件随机修改<ol>
<li>一个文件只能有一个写，不允许多个线程同时写</li>
<li>仅支持数据追加（append），不支持文件随机修改</li>
</ol>
</li>
</ol>
<h2 id="2-2-组成架构"><a href="#2-2-组成架构" class="headerlink" title="2.2. 组成架构"></a>2.2. 组成架构</h2><p><img src="//bruceeezhao.github.io/2020/11/05/Hadoop/hdfsarchitecture.png" alt></p>
<ol>
<li>NameNode: （master）<ol>
<li>管理HDFS的名称空间</li>
<li>配置副本策略</li>
<li>管理数据块（Block）映射信息</li>
<li>处理客户端读写请求</li>
</ol>
</li>
<li>DataNode: （slave）<ol>
<li>存储实际的数据块</li>
<li>执行数据块的读写操作</li>
</ol>
</li>
<li>client<ol>
<li>文件切分。文件上传HDFS的时候，Client将文件切分成多个Block，然后上传。</li>
<li>与NameNode交互，获取文件的位置信息。</li>
<li>与DataNode交互，读取或写入数据。</li>
<li>Client提供一些命令管理HDFS</li>
<li>通过命令访问HDFS，如增删查改等</li>
</ol>
</li>
<li>Secondary NameNode：并非NameNode的热备。当NameNode挂掉的时候并不能马上替换NameNode并提供服务<ol>
<li>复制NameNode，分担其工作，如定期合并Fsimage和Edits，并推送给NameNode</li>
<li>在紧急情况下，可辅助恢复NameNode</li>
</ol>
</li>
</ol>
<h3 id="2-2-1-文件块大小（面试题）"><a href="#2-2-1-文件块大小（面试题）" class="headerlink" title="2.2.1. 文件块大小（面试题）"></a>2.2.1. 文件块大小（面试题）</h3><p>通过配置参数 <code>dfs.blocksize</code>来确定，默认大小在Hadoop2.x中是128M，老版本中是64M。这个大小是根据寻址时间和硬盘写入速度确定的，最佳状态是寻址时间是传输时间的1%。按寻址时间10ms，传输速度100M/s来计算，块大小需为100M。</p>
<p>块设置很小，就会增加寻址时间；如果太大，传输数据的时间会明显大于寻址时间。</p>
<h2 id="2-3-HDFS-API"><a href="#2-3-HDFS-API" class="headerlink" title="2.3. HDFS API"></a>2.3. HDFS API</h2><h3 id="2-3-1-环境配置"><a href="#2-3-1-环境配置" class="headerlink" title="2.3.1. 环境配置"></a>2.3.1. 环境配置</h3><ol>
<li><p>新建mvn工程</p>
</li>
<li><p>添加依赖</p>
<p>在<a href="https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-client/2.9.2" target="_blank" rel="noopener">https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-client/2.9.2</a> 选择与部署hadoop版本相同的mvn依赖，并添加依赖</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- https://mvnrepository.com/artifact/org.apache.hadoop/hadoop-client --&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">          <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.9.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>配置log4j</p>
<ol>
<li><p>新建log4j.properties文件</p>
</li>
<li><p>把下面的内容添加到文件中</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">### 设置###</span><br><span class="line">log4j.rootLogger = info,stdout,D,E</span><br><span class="line"></span><br><span class="line">### 输出信息到控制抬 ###</span><br><span class="line">log4j.appender.stdout = org.apache.log4j.ConsoleAppender</span><br><span class="line">log4j.appender.stdout.Target = System.out</span><br><span class="line">log4j.appender.stdout.layout = org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.stdout.layout.ConversionPattern = [%-5p] %d&#123;yyyy-MM-dd HH:mm:ss,SSS&#125; method:%l%n%m%n</span><br><span class="line"></span><br><span class="line">### 输出DEBUG 级别以上的日志到=E://logs/error.log ###</span><br><span class="line">log4j.appender.D = org.apache.log4j.DailyRollingFileAppender</span><br><span class="line">log4j.appender.D.File = ./logs/log.log</span><br><span class="line">log4j.appender.D.Append = true</span><br><span class="line">log4j.appender.D.Threshold = DEBUG</span><br><span class="line">log4j.appender.D.layout = org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.D.layout.ConversionPattern = %-d&#123;yyyy-MM-dd HH:mm:ss&#125;  [ %t:%r ] - [ %p ]  %m%n</span><br><span class="line"></span><br><span class="line">### 输出ERROR 级别以上的日志到=E://logs/error.log ###</span><br><span class="line">log4j.appender.E = org.apache.log4j.DailyRollingFileAppender</span><br><span class="line">log4j.appender.E.File =./logs/error.log</span><br><span class="line">log4j.appender.E.Append = true</span><br><span class="line">log4j.appender.E.Threshold = ERROR</span><br><span class="line">log4j.appender.E.layout = org.apache.log4j.PatternLayout</span><br><span class="line">log4j.appender.E.layout.ConversionPattern = %-d&#123;yyyy-MM-dd HH:mm:ss&#125;  [ %t:%r ] - [ %p ]  %m%n</span><br></pre></td></tr></table></figure>
</li>
</ol>
</li>
<li><p>测试</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HDFSClient</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        HDFSClient h = <span class="keyword">new</span> HDFSClient();</span><br><span class="line">        h.test();</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 0 一个简单的测试</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">test</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://localhost:9091"</span>);</span><br><span class="line">        FileSystem fs = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 1 获取hdfs客户端对象</span></span><br><span class="line">            fs = FileSystem.get(conf);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 2 在hdfs上创建路径</span></span><br><span class="line">            fs.mkdirs(<span class="keyword">new</span> Path(<span class="string">"/1109/dashi"</span>));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 3 关闭资源</span></span><br><span class="line">            fs.close();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        System.out.println(<span class="string">"over"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>执行结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ hadoop fs -ls /</span><br><span class="line">Found 1 items</span><br><span class="line">drwxr-xr-x   - bruce supergroup          0 2020-11-10 10:56 /1109</span><br></pre></td></tr></table></figure>

</li>
</ol>
<h3 id="2-3-2-上传文件"><a href="#2-3-2-上传文件" class="headerlink" title="2.3.2. 上传文件"></a>2.3.2. 上传文件</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1 文件上传</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testCopyFromLoaclFile</span><span class="params">()</span> </span>&#123;</span><br><span class="line">       <span class="comment">// 获取fs对象</span></span><br><span class="line">       Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">       conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://localhost:9091"</span>);</span><br><span class="line">       FileSystem fs = <span class="keyword">null</span>;</span><br><span class="line">       <span class="keyword">try</span> &#123;</span><br><span class="line">           fs = FileSystem.get(conf);</span><br><span class="line"></span><br><span class="line">           <span class="comment">// 执行上传api</span></span><br><span class="line">           fs.copyFromLocalFile(<span class="keyword">new</span> Path(<span class="string">"/home/bruce/Desktop/hadooptest.txt"</span>), <span class="keyword">new</span> Path(<span class="string">"/hadooptest.txt"</span>));</span><br><span class="line"></span><br><span class="line">           <span class="comment">// 关闭资源</span></span><br><span class="line">           fs.close();</span><br><span class="line">       &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">           e.printStackTrace();</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<p>执行结果</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ hadoop fs -ls /</span><br><span class="line">Found 2 items</span><br><span class="line">drwxr-xr-x   - bruce supergroup          0 2020-11-10 10:56 /1109</span><br><span class="line">-rw-r--r--   3 bruce supergroup         97 2020-11-10 11:15 /hadooptest.txt</span><br></pre></td></tr></table></figure>

<h3 id="2-3-3-下载文件"><a href="#2-3-3-下载文件" class="headerlink" title="2.3.3. 下载文件"></a>2.3.3. 下载文件</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 2 文件下载</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testCopyToLocalFile</span><span class="params">()</span> </span>&#123;</span><br><span class="line">       <span class="comment">// 获取fs对象</span></span><br><span class="line">       Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">       conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://localhost:9091"</span>);</span><br><span class="line">       FileSystem fs = <span class="keyword">null</span>;</span><br><span class="line">       <span class="keyword">try</span> &#123;</span><br><span class="line">           fs = FileSystem.get(conf);</span><br><span class="line"></span><br><span class="line">           <span class="comment">// 执行下载api</span></span><br><span class="line">           fs.copyToLocalFile(<span class="keyword">new</span> Path(<span class="string">"/hadooptest.txt"</span>), <span class="keyword">new</span> Path(<span class="string">"./hadoop.txt"</span>));</span><br><span class="line">           <span class="comment">// 关闭资源</span></span><br><span class="line">           fs.close();</span><br><span class="line">       &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">           e.printStackTrace();</span><br><span class="line">       &#125;</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-3-4-文件删除"><a href="#2-3-4-文件删除" class="headerlink" title="2.3.4. 文件删除"></a>2.3.4. 文件删除</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 3 文件删除</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testDelete</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 获取fs对象</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://localhost:9091"</span>);</span><br><span class="line">        FileSystem fs = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            fs = FileSystem.get(conf);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 执行删除api</span></span><br><span class="line">            fs.delete(<span class="keyword">new</span> Path(<span class="string">"/hadooptest.txt"</span>));</span><br><span class="line">            <span class="comment">// 关闭资源</span></span><br><span class="line">            fs.close();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-3-5-文件信息打印"><a href="#2-3-5-文件信息打印" class="headerlink" title="2.3.5. 文件信息打印"></a>2.3.5. 文件信息打印</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 4 查看文件信息</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testListFiles</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 获取fs对象</span></span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://localhost:9091"</span>);</span><br><span class="line">        FileSystem fs = <span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            fs = FileSystem.get(conf);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 查看文件信息</span></span><br><span class="line">            RemoteIterator&lt;LocatedFileStatus&gt; listFiles = fs.listFiles(<span class="keyword">new</span> Path(<span class="string">"/"</span>), <span class="keyword">true</span>);</span><br><span class="line">            <span class="keyword">while</span> (listFiles.hasNext()) &#123;</span><br><span class="line">                LocatedFileStatus fileStatus = listFiles.next();</span><br><span class="line">                System.out.println(fileStatus.getPath().getName());</span><br><span class="line">                System.out.println(fileStatus.getPermission());</span><br><span class="line">                System.out.println(fileStatus.getLen());</span><br><span class="line"></span><br><span class="line">                BlockLocation[] blockLocations = fileStatus.getBlockLocations();</span><br><span class="line">                <span class="keyword">for</span> (BlockLocation block: blockLocations</span><br><span class="line">                     ) &#123;</span><br><span class="line">                    String[] hosts = block.getHosts();</span><br><span class="line"></span><br><span class="line">                    <span class="keyword">for</span> (String host: hosts) &#123;</span><br><span class="line">                        System.out.println(host);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                System.out.println(<span class="string">"===================="</span>);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 关闭资源</span></span><br><span class="line">            fs.close();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h2 id="2-4-HDFS-I-O流操作"><a href="#2-4-HDFS-I-O流操作" class="headerlink" title="2.4. HDFS I/O流操作"></a>2.4. HDFS I/O流操作</h2><h3 id="2-4-1-上传文件"><a href="#2-4-1-上传文件" class="headerlink" title="2.4.1. 上传文件"></a>2.4.1. 上传文件</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 上传文件</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testUpLoadFile</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://localhost:9091"</span>);</span><br><span class="line">        FileSystem fs = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 1 获取对象</span></span><br><span class="line">            fs = FileSystem.get(conf);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 2 获取输入流</span></span><br><span class="line">            FileInputStream fis = <span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> File(<span class="string">"/home/bruce/Desktop/hadooptest.txt"</span>));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 3 获取输出流</span></span><br><span class="line">            FSDataOutputStream fos = fs.create(<span class="keyword">new</span> Path(<span class="string">"/zhangsan.txt"</span>));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 4 流的对烤</span></span><br><span class="line">            IOUtils.copyBytes(fis, fos, conf);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 5 关闭资源</span></span><br><span class="line">            IOUtils.closeStream(fis);</span><br><span class="line">            IOUtils.closeStream(fos);</span><br><span class="line">            fs.close();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-4-2-下载文件"><a href="#2-4-2-下载文件" class="headerlink" title="2.4.2. 下载文件"></a>2.4.2. 下载文件</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 下载文件</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">testDownFile</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://localhost:9091"</span>);</span><br><span class="line">        FileSystem fs = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 1 获取对象</span></span><br><span class="line">            fs = FileSystem.get(conf);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 2 获取输入流</span></span><br><span class="line">            FSDataInputStream fis = fs.open(<span class="keyword">new</span> Path(<span class="string">"/zhangsan.txt"</span>));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 3 获取输出流</span></span><br><span class="line">            FileOutputStream fos = <span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(<span class="string">"./lisi.txt"</span>));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 4 流的对烤</span></span><br><span class="line">            IOUtils.copyBytes(fis, fos, conf);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 5 关闭资源</span></span><br><span class="line">            IOUtils.closeStream(fis);</span><br><span class="line">            IOUtils.closeStream(fos);</span><br><span class="line">            fs.close();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h3 id="2-4-3-读取部分文件"><a href="#2-4-3-读取部分文件" class="headerlink" title="2.4.3. 读取部分文件"></a>2.4.3. 读取部分文件</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//读取部分内容</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">readFileSeek</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">        conf.set(<span class="string">"fs.defaultFS"</span>, <span class="string">"hdfs://localhost:9091"</span>);</span><br><span class="line">        FileSystem fs = <span class="keyword">null</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 1 获取对象</span></span><br><span class="line">            fs = FileSystem.get(conf);</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 2 获取输入流</span></span><br><span class="line">            FSDataInputStream fis = fs.open(<span class="keyword">new</span> Path(<span class="string">"/zhangsan.txt"</span>));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 3 获取输出流</span></span><br><span class="line">            FileOutputStream fos = <span class="keyword">new</span> FileOutputStream(<span class="keyword">new</span> File(<span class="string">"./wangwu.txt"</span>));</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 4 流的对烤</span></span><br><span class="line">            <span class="keyword">byte</span>[] bytes = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i&lt;<span class="number">1</span> ; i++) &#123;</span><br><span class="line">                <span class="keyword">int</span> len = fis.read(bytes,<span class="number">0</span>, <span class="number">5</span>);</span><br><span class="line">                fos.write(bytes,<span class="number">0</span>, <span class="number">5</span>);</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="comment">// 5 关闭资源</span></span><br><span class="line">            fis.close();</span><br><span class="line">            fos.close();</span><br><span class="line">            fs.close();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<h2 id="2-5-HDFS数据流"><a href="#2-5-HDFS数据流" class="headerlink" title="2.5. HDFS数据流"></a>2.5. HDFS数据流</h2><h3 id="2-5-1-写入流程"><a href="#2-5-1-写入流程" class="headerlink" title="2.5.1. 写入流程"></a>2.5.1. 写入流程</h3><h4 id="2-5-1-1-数据写入"><a href="#2-5-1-1-数据写入" class="headerlink" title="2.5.1.1. 数据写入"></a>2.5.1.1. 数据写入</h4><p><img src="//bruceeezhao.github.io/2020/11/05/Hadoop/writeProcess.png" alt></p>
<h4 id="2-5-1-2-副本存储节点选择"><a href="#2-5-1-2-副本存储节点选择" class="headerlink" title="2.5.1.2. 副本存储节点选择"></a>2.5.1.2. 副本存储节点选择</h4><p>文档版本 - 3.2.1</p>
<p>在副本数量为3的情况下：</p>
<ol>
<li>如果writer在一个datanode上，那么第一个副本就存储在这个datanode上，否则选择与writer在同一个机架的随机节点。</li>
<li>第二个节点选择在不同机架的一个datanode</li>
<li>第三个节点选择在不同机架上的与第二个节点不同的datanode</li>
</ol>
<p>如果复制因子大于3，则随机决定第4个副本和后面的副本的位置，同时保持每个机架的副本数量低于上限(基本上是(副本数 - 1) /机架+ 2)。</p>
<p><img src="//bruceeezhao.github.io/2020/11/05/Hadoop/replicaSelection.png" alt></p>
<p>因为NameNode不允许数据节点拥有同一个块的多个副本，所以创建的副本的最大数量是当前数据节点的总数。</p>
<h4 id="2-5-1-3-节点距离的计算"><a href="#2-5-1-3-节点距离的计算" class="headerlink" title="2.5.1.3. 节点距离的计算"></a>2.5.1.3. 节点距离的计算</h4><p>在HDFS读写数据的过程中，NameNode会选择距离待上传/下载数据最近距离的Datanode。</p>
<p>节点距离 = 两个节点到达最近共同祖先的距离总和。</p>
<p><img src="//bruceeezhao.github.io/2020/11/05/Hadoop/datanodeDistance.png" alt></p>
<p>distance(00, 00) = 0  (同一节点上的进程)</p>
<p>distance(00, 01) = 2  (同一机架上的不同节点) </p>
<p>distance(00, 05) = 4  (同一数据中心，不同机架上的节点)</p>
<p>distance(00, 15) = 6  (不同数据中心的节点)</p>
<h3 id="2-5-2-读取流程"><a href="#2-5-2-读取流程" class="headerlink" title="2.5.2. 读取流程"></a>2.5.2. 读取流程</h3><p><img src="//bruceeezhao.github.io/2020/11/05/Hadoop/readProcess.png" alt></p>
<h2 id="2-6-NameNode和Secondary-NameNode"><a href="#2-6-NameNode和Secondary-NameNode" class="headerlink" title="2.6. NameNode和Secondary NameNode"></a>2.6. NameNode和Secondary NameNode</h2><h3 id="2-6-1-工作机制"><a href="#2-6-1-工作机制" class="headerlink" title="2.6.1. 工作机制"></a>2.6.1. 工作机制</h3><ol>
<li><p>NameNode的元数据存放在内存中，为了防止断电丢失，在磁盘中存一个备份FsImage。</p>
</li>
<li><p>这样带来新的问题，如果在内存中更新的同时更新fsimage，就会导致效率过低，如果不更新，就会发生一致性问题，一旦NameNode断电，就会产生数据丢失。因此，引入<strong>Edits</strong>文件（只进行追加操作，效率很高）。每当元数据有更新或添加元数据时，修改内存中的元数据并追加到Edits中（先更新Edits再更新内存）。这样，一旦NameNode断电，可以通过fsimage和Edits的合并，合成元数据。</p>
</li>
<li><p>如果长时间添加数据到Edits中，会导致文件数据过大，效率降低，一旦断电，恢复元数据需要的时间很长。因此需要定期进行fsimage和Edits的合并。合并操作由Secondary NameNode完成。</p>
</li>
</ol>
<p><img src="//bruceeezhao.github.io/2020/11/05/Hadoop/namenodeWork.png" alt></p>
<p><strong>tips</strong>[hdfs-default.xml]</p>
<ol>
<li>定时时间默认3600秒</li>
<li>edits中的数据大于100万条，每隔60秒检查一次。</li>
</ol>
<h3 id="2-6-2-Fsimage-和-Edits"><a href="#2-6-2-Fsimage-和-Edits" class="headerlink" title="2.6.2. Fsimage 和 Edits"></a>2.6.2. Fsimage 和 Edits</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">/tmp/hadoop-bruce/dfs/name/current$ ls</span><br><span class="line">edits_0000000000000000001-0000000000000000002  fsimage_0000000000000000004</span><br><span class="line">edits_0000000000000000003-0000000000000000004  fsimage_0000000000000000004.md5</span><br><span class="line">edits_inprogress_0000000000000000005           seen_txid</span><br><span class="line">fsimage_0000000000000000002                    VERSION</span><br><span class="line">fsimage_0000000000000000002.md5</span><br></pre></td></tr></table></figure>

<ol>
<li>fsimage文件：HDFS文件系统元数据的一个永久性检查点，其中包括HDFS文件系统的所有目录和文件idnode的序列化信息。</li>
<li>edits文件：存放HDFS文件系统的所有更新操作的路径，文件系统客户端执行的所有写操作首先会被记录到edits文件中</li>
<li>seen_txid文件：保存的是一个数字，就是最后一个edits的数字</li>
<li>每次namenode启动时都会将fsimage文件读入内存，加载edits里面的更新操作，保证内存中的元数据信息是最新的、同步的，可以看成namenode启动的时候就将fsiamge和edits文件进行了合并。</li>
</ol>
<p>在hdfs中新建目录</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -mkdir /zhao</span><br></pre></td></tr></table></figure>

<p>查看操作日志</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/tmp/hadoop-bruce/dfs/name/current$ hdfs oev -p XML -i edits_inprogress_0000000000000000005 -o ed.xml</span><br><span class="line">/tmp/hadoop-bruce/dfs/name/current$ cat ed.xml</span><br></pre></td></tr></table></figure>

<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">EDITS</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">EDITS_VERSION</span>&gt;</span>-63<span class="tag">&lt;/<span class="name">EDITS_VERSION</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_START_LOG_SEGMENT<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">DATA</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">TXID</span>&gt;</span>5<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">RECORD</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">OPCODE</span>&gt;</span>OP_MKDIR<span class="tag">&lt;/<span class="name">OPCODE</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">DATA</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">TXID</span>&gt;</span>6<span class="tag">&lt;/<span class="name">TXID</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">LENGTH</span>&gt;</span>0<span class="tag">&lt;/<span class="name">LENGTH</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">INODEID</span>&gt;</span>16386<span class="tag">&lt;/<span class="name">INODEID</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">PATH</span>&gt;</span>/zhao<span class="tag">&lt;/<span class="name">PATH</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">TIMESTAMP</span>&gt;</span>1605182998565<span class="tag">&lt;/<span class="name">TIMESTAMP</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">PERMISSION_STATUS</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">USERNAME</span>&gt;</span>bruce<span class="tag">&lt;/<span class="name">USERNAME</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">GROUPNAME</span>&gt;</span>supergroup<span class="tag">&lt;/<span class="name">GROUPNAME</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">MODE</span>&gt;</span>493<span class="tag">&lt;/<span class="name">MODE</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;/<span class="name">PERMISSION_STATUS</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">DATA</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">RECORD</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">EDITS</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h2 id="2-7-Datanode（面试重点）"><a href="#2-7-Datanode（面试重点）" class="headerlink" title="2.7. Datanode（面试重点）"></a>2.7. Datanode（面试重点）</h2><h3 id="2-7-1-工作机制"><a href="#2-7-1-工作机制" class="headerlink" title="2.7.1. 工作机制"></a>2.7.1. 工作机制</h3><p><img src="//bruceeezhao.github.io/2020/11/05/Hadoop/datanodeWork.png" alt></p>
<ol>
<li>一个数据块在Datanode上以文件形式存储在磁盘上，包括两个文件，一个是数据本身，一个是元数据包括数据块的长度，块数据的校验和，以及时间戳</li>
<li>Datanode启动后向NameNode注册，通过后，周期性（1小时）的向Namenode上报所有块的信息</li>
<li>心跳3秒一次，心跳返回结果带有Namenode给该Datanode的命令，如复制块数据到另一台机器，或删除某个数据块。如果超过10分钟没有收到某个Datanode的心跳，则认为该节点不可用。</li>
<li>集群运行中可以安全加入或退出一些机器</li>
</ol>
<h3 id="2-7-2-数据完整性"><a href="#2-7-2-数据完整性" class="headerlink" title="2.7.2. 数据完整性"></a>2.7.2. 数据完整性</h3><ol>
<li>当Datanode读取Block的时候，它会计算CheckSum</li>
<li>如果计算后的CheckSum，与创建时值不一样，说明Block已经损坏</li>
<li>Client读取其他Datanode上的Block</li>
<li>Datanode在其文件创建后周期验证CheckSum</li>
</ol>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/大数据/" rel="tag"># 大数据</a>
              <a href="/tags/Hadoop/" rel="tag"># Hadoop</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/11/01/Java多线程/" rel="prev" title="Java多线程">
      <i class="fa fa-chevron-left"></i> Java多线程
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/11/06/设计模式学习之-04工厂模式/" rel="next" title="设计模式学习之-04工厂模式">
      设计模式学习之-04工厂模式 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-Hadoop初识"><span class="nav-number">1.</span> <span class="nav-text">1. Hadoop初识</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-1-Hadoop1-x-与-2-x的区别"><span class="nav-number">1.1.</span> <span class="nav-text">1.1. Hadoop1.x 与 2.x的区别</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-2-HDFS架构"><span class="nav-number">1.2.</span> <span class="nav-text">1.2. HDFS架构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-3-Yarn架构"><span class="nav-number">1.3.</span> <span class="nav-text">1.3. Yarn架构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-4-MapReduce"><span class="nav-number">1.4.</span> <span class="nav-text">1.4. MapReduce</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-HDFS"><span class="nav-number">2.</span> <span class="nav-text">2. HDFS</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-优缺点"><span class="nav-number">2.1.</span> <span class="nav-text">2.1. 优缺点</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-1-优点"><span class="nav-number">2.1.1.</span> <span class="nav-text">2.1.1. 优点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-2-缺点"><span class="nav-number">2.1.2.</span> <span class="nav-text">2.1.2. 缺点</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-组成架构"><span class="nav-number">2.2.</span> <span class="nav-text">2.2. 组成架构</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-1-文件块大小（面试题）"><span class="nav-number">2.2.1.</span> <span class="nav-text">2.2.1. 文件块大小（面试题）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-HDFS-API"><span class="nav-number">2.3.</span> <span class="nav-text">2.3. HDFS API</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-1-环境配置"><span class="nav-number">2.3.1.</span> <span class="nav-text">2.3.1. 环境配置</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-2-上传文件"><span class="nav-number">2.3.2.</span> <span class="nav-text">2.3.2. 上传文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-3-下载文件"><span class="nav-number">2.3.3.</span> <span class="nav-text">2.3.3. 下载文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-4-文件删除"><span class="nav-number">2.3.4.</span> <span class="nav-text">2.3.4. 文件删除</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-5-文件信息打印"><span class="nav-number">2.3.5.</span> <span class="nav-text">2.3.5. 文件信息打印</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-4-HDFS-I-O流操作"><span class="nav-number">2.4.</span> <span class="nav-text">2.4. HDFS I/O流操作</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-1-上传文件"><span class="nav-number">2.4.1.</span> <span class="nav-text">2.4.1. 上传文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-2-下载文件"><span class="nav-number">2.4.2.</span> <span class="nav-text">2.4.2. 下载文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-3-读取部分文件"><span class="nav-number">2.4.3.</span> <span class="nav-text">2.4.3. 读取部分文件</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-5-HDFS数据流"><span class="nav-number">2.5.</span> <span class="nav-text">2.5. HDFS数据流</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-5-1-写入流程"><span class="nav-number">2.5.1.</span> <span class="nav-text">2.5.1. 写入流程</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#2-5-1-1-数据写入"><span class="nav-number">2.5.1.1.</span> <span class="nav-text">2.5.1.1. 数据写入</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-5-1-2-副本存储节点选择"><span class="nav-number">2.5.1.2.</span> <span class="nav-text">2.5.1.2. 副本存储节点选择</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-5-1-3-节点距离的计算"><span class="nav-number">2.5.1.3.</span> <span class="nav-text">2.5.1.3. 节点距离的计算</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-5-2-读取流程"><span class="nav-number">2.5.2.</span> <span class="nav-text">2.5.2. 读取流程</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-6-NameNode和Secondary-NameNode"><span class="nav-number">2.6.</span> <span class="nav-text">2.6. NameNode和Secondary NameNode</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-6-1-工作机制"><span class="nav-number">2.6.1.</span> <span class="nav-text">2.6.1. 工作机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-6-2-Fsimage-和-Edits"><span class="nav-number">2.6.2.</span> <span class="nav-text">2.6.2. Fsimage 和 Edits</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-7-Datanode（面试重点）"><span class="nav-number">2.7.</span> <span class="nav-text">2.7. Datanode（面试重点）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-7-1-工作机制"><span class="nav-number">2.7.1.</span> <span class="nav-text">2.7.1. 工作机制</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-7-2-数据完整性"><span class="nav-number">2.7.2.</span> <span class="nav-text">2.7.2. 数据完整性</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">bruce zhao</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">24</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">16</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/bruceEeZhao" title="GitHub → https://github.com/bruceEeZhao" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="/bruceezhao@foxmail.com" title="E-Mail → bruceezhao@foxmail.com"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/null" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">bruce zhao</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.9.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://muse.theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.5.0
  </div>

        








        
      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script>
<script src="/js/schemes/muse.js"></script>
<script src="/js/next-boot.js"></script>



  
















  

  

</body>
</html>
